{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предлагаю идти по следующему плану:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.**\n",
    "\n",
    "        1.1 загрузка, знакомство с данными\n",
    "        1.2 лемматизация\n",
    "        1.3 разбиение данных на выборки: train, valid, test.\n",
    "        1.4 преобразование выборок в матрицы tf_idf\n",
    "        \n",
    "**2.**\n",
    "\n",
    "        2.1 подбор параметров, обучение моделей и тестировоание на валидационой выборке\n",
    "        2.2 выбор лучших из обученных моделей и тестирование на тестовой выборке\n",
    "\n",
    "**3**\n",
    "\n",
    "        3.1 финальный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Набор инструментов:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_curve, roc_auc_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и ознакомимся с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по всему язык комментариев - английский."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Определим длину самого длинного комментария"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_twit = 0\n",
    "ind = 0\n",
    "for i in range(len(df)):\n",
    "    if len(df['text'].loc[i]) > len_twit:\n",
    "        len_twit = len(df['text'].loc[i])\n",
    "        ind = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_twit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5000 символов - как небольшой рассказ. Я посмотрел его - повторяющиеся спамерские фразы, аналогично и с комментариями в 4997, 4994. \n",
    "\n",
    "Комментарии представляют собой спам в виде повторяющихся фраз или слов. Я бы дополнил модель машинного обучения функцией, которая прежде, чем отправить данные на анализ модели, смотрела есть ли повторы в комментариях - можно ли его разделить на несколько идентичных фрагментов, если да - даже не отправлять на модерацию, а сразу удалять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим насколько сбалансированы классы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы несбалансированные. Имея опыт работы по прошлым проектам - лучший результат, если работать с решающим деревом или случайным лесом - получается, если модель учится на несбалансированной выборке, но с изменением веса класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация и токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в сети прочитал, что pymystem не самый оптимальный инструмент. Давайте посмотрим на время выполнения однотипной процедуры разными лемматизаторами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "aa = m.lemmatize('Caring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caring', '\\n']\n",
      "CPU times: user 680 µs, sys: 64 µs, total: 744 µs\n",
      "Wall time: 15.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(m.lemmatize('Caring'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caring\n",
      "CPU times: user 3.07 s, sys: 183 ms, total: 3.25 s\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(lemmatizer.lemmatize(\"caring\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выбор очевиден! \n",
    "\n",
    "Далее работаем с лемматизатором nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед лемматизацией нужно очистить текст от ненужных символов.\n",
    "\n",
    "Для этого напишем функции:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. для лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    m = WordNetLemmatizer()\n",
    "    lemm_list = m.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list) \n",
    "        \n",
    "    return(lemm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. для очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    re_list = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
    "    re_list = re_list.split()\n",
    "    re_list = \" \".join(re_list)\n",
    "    return(re_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация\n",
    "\n",
    "Старший товарищ (наш наставник помощник, консультант и мастер в Slack) сообщил, что для Puthon 3 приводить текст в юникод нет надобности. (если я верно понял: \" у нас тут третий питончик, в юникод ничего преобразовывать не надо.\", хотя в тренажере мы преобразовывали)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['text'].apply(lambda x: lemmatize(clear_text(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подготовили наш текст для анализа:\n",
    "    \n",
    "    очистили его от ненужных символов\n",
    "    лемматизировали"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "теперь разделим на тренировочную, валидационную и тестовую выборки и подготовим матрицу tf_idf.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим признаки - (наш текст) и целевой признак - df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(corpus, target, test_size=0.4, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получив выборки, подготовим матрицы tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучим на тренировочной выборке и преобразуем наши выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "\n",
    "tf_idf_maker = count_tf_idf.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf_idf_maker.transform(x_train)\n",
    "x_val = tf_idf_maker.transform(x_val)\n",
    "x_test = tf_idf_maker.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод по шагу**\n",
    "\n",
    "Посмотрели на данные - без пропусков.\n",
    "\n",
    "Классы не сбалансирвоаны, но попробуем поработать с несбалансированными выборками, изменяя вес класса.\n",
    "\n",
    "Познакомились с примерами комментариев.\n",
    "\n",
    "Подготовили тренировочную, валидационную и тестовую выборки в виде матрицы tf_idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом шаге обучим следующие моделиЖ\n",
    "\n",
    "    1. Логистическаая регрессия\n",
    "    2. Дерево решений\n",
    "    3. Случайный лес\n",
    "    4. Cat-boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная метрика - f1, но нужно заметить, что токсических комментариев меньше, но пропускать их категорически нельзя. Я считаю, что тут очень важны precision - как долz объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall как доля объектов положительного класса из всех объектов положительного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshould: 0.0\n",
      "recall: 1.0\n",
      "precision: 0.10064548474023939\n",
      "f1: 0.18288447303991345\n",
      "AUC-ROC 0.5\n",
      "\n",
      "\n",
      "threshould: 0.02\n",
      "recall: 0.9996886674968867\n",
      "precision: 0.11667453944260746\n",
      "f1: 0.20896105163830406\n",
      "AUC-ROC 0.5763546814594043\n",
      "\n",
      "\n",
      "threshould: 0.04\n",
      "recall: 0.99906600249066\n",
      "precision: 0.1377371448192978\n",
      "f1: 0.24209732176537158\n",
      "AUC-ROC 0.6495748101785054\n",
      "\n",
      "\n",
      "threshould: 0.06\n",
      "recall: 0.9962640099626401\n",
      "precision: 0.16103869961250064\n",
      "f1: 0.27726032144868523\n",
      "AUC-ROC 0.7077167029117779\n",
      "\n",
      "\n",
      "threshould: 0.08\n",
      "recall: 0.9940846824408468\n",
      "precision: 0.18632199334772714\n",
      "f1: 0.3138237751240847\n",
      "AUC-ROC 0.7541324394714164\n",
      "\n",
      "\n",
      "threshould: 0.1\n",
      "recall: 0.9897260273972602\n",
      "precision: 0.2114962411017231\n",
      "f1: 0.3485172394891191\n",
      "AUC-ROC 0.7883965653675034\n",
      "\n",
      "\n",
      "threshould: 0.12\n",
      "recall: 0.9850560398505604\n",
      "precision: 0.23798420458819106\n",
      "f1: 0.38335251711395163\n",
      "AUC-ROC 0.8160420607586716\n",
      "\n",
      "\n",
      "threshould: 0.14\n",
      "recall: 0.9797633872976339\n",
      "precision: 0.26445378151260507\n",
      "f1: 0.41649020645844365\n",
      "AUC-ROC 0.8374010302804106\n",
      "\n",
      "\n",
      "threshould: 0.16\n",
      "recall: 0.973225404732254\n",
      "precision: 0.2928062944923192\n",
      "f1: 0.4501728110599078\n",
      "AUC-ROC 0.8550887667518842\n",
      "\n",
      "\n",
      "threshould: 0.18\n",
      "recall: 0.9673100871731009\n",
      "precision: 0.3220356550580431\n",
      "f1: 0.483203732503888\n",
      "AUC-ROC 0.8697082802947937\n",
      "\n",
      "\n",
      "threshould: 0.2\n",
      "recall: 0.9620174346201743\n",
      "precision: 0.3498245216800634\n",
      "f1: 0.5130759651307596\n",
      "AUC-ROC 0.8809634242991472\n",
      "\n",
      "\n",
      "threshould: 0.22\n",
      "recall: 0.9567247820672479\n",
      "precision: 0.3780292778939599\n",
      "f1: 0.5419275196190813\n",
      "AUC-ROC 0.8902849051441388\n",
      "\n",
      "\n",
      "threshould: 0.24\n",
      "recall: 0.9495641344956414\n",
      "precision: 0.40520791816128604\n",
      "f1: 0.5680230933978955\n",
      "AUC-ROC 0.8967909864868981\n",
      "\n",
      "\n",
      "threshould: 0.26\n",
      "recall: 0.9417808219178082\n",
      "precision: 0.43331900873800316\n",
      "f1: 0.5935445894241146\n",
      "AUC-ROC 0.9019753527748055\n",
      "\n",
      "\n",
      "threshould: 0.28\n",
      "recall: 0.9318181818181818\n",
      "precision: 0.45841629652320415\n",
      "f1: 0.6145159634534442\n",
      "AUC-ROC 0.9043105960306852\n",
      "\n",
      "\n",
      "threshould: 0.3\n",
      "recall: 0.9255915317559154\n",
      "precision: 0.4825515338419088\n",
      "f1: 0.6343753334044596\n",
      "AUC-ROC 0.9072595663099834\n",
      "\n",
      "\n",
      "threshould: 0.32\n",
      "recall: 0.9184308841843088\n",
      "precision: 0.5053966078464965\n",
      "f1: 0.652005746491325\n",
      "AUC-ROC 0.9089227795599266\n",
      "\n",
      "\n",
      "threshould: 0.34\n",
      "recall: 0.9115815691158157\n",
      "precision: 0.5291885053316465\n",
      "f1: 0.6696397941680962\n",
      "AUC-ROC 0.9104106716737883\n",
      "\n",
      "\n",
      "threshould: 0.36\n",
      "recall: 0.901307596513076\n",
      "precision: 0.5514285714285714\n",
      "f1: 0.6842354053415267\n",
      "AUC-ROC 0.909628782578188\n",
      "\n",
      "\n",
      "threshould: 0.38\n",
      "recall: 0.8925902864259029\n",
      "precision: 0.5707744375870993\n",
      "f1: 0.6962962962962962\n",
      "AUC-ROC 0.908736784910394\n",
      "\n",
      "\n",
      "threshould: 0.4\n",
      "recall: 0.885118306351183\n",
      "precision: 0.5914291657998751\n",
      "f1: 0.7090659683252275\n",
      "AUC-ROC 0.9083455095270652\n",
      "\n",
      "\n",
      "threshould: 0.42\n",
      "recall: 0.8816936488169365\n",
      "precision: 0.6141834743005855\n",
      "f1: 0.7240189185734373\n",
      "AUC-ROC 0.9098559526922115\n",
      "\n",
      "\n",
      "threshould: 0.44\n",
      "recall: 0.8739103362391034\n",
      "precision: 0.6340637000225886\n",
      "f1: 0.734912946720775\n",
      "AUC-ROC 0.9087341382261646\n",
      "\n",
      "\n",
      "threshould: 0.46\n",
      "recall: 0.8651930261519303\n",
      "precision: 0.6535747883349012\n",
      "f1: 0.744640943193998\n",
      "AUC-ROC 0.9069362803395705\n",
      "\n",
      "\n",
      "threshould: 0.48\n",
      "recall: 0.8564757160647571\n",
      "precision: 0.671630859375\n",
      "f1: 0.7528735632183908\n",
      "AUC-ROC 0.904807435065338\n",
      "\n",
      "\n",
      "threshould: 0.5\n",
      "recall: 0.8465130759651308\n",
      "precision: 0.6890522047643183\n",
      "f1: 0.7597094160379995\n",
      "AUC-ROC 0.9018817208966481\n",
      "\n",
      "\n",
      "threshould: 0.52\n",
      "recall: 0.8365504358655044\n",
      "precision: 0.7059905412506569\n",
      "f1: 0.7657452265602737\n",
      "AUC-ROC 0.8987818028397274\n",
      "\n",
      "\n",
      "threshould: 0.54\n",
      "recall: 0.8262764632627646\n",
      "precision: 0.7245427245427245\n",
      "f1: 0.7720727272727272\n",
      "AUC-ROC 0.8955610593088961\n",
      "\n",
      "\n",
      "threshould: 0.56\n",
      "recall: 0.8169364881693649\n",
      "precision: 0.7387387387387387\n",
      "f1: 0.7758722649319929\n",
      "AUC-ROC 0.8923021232568656\n",
      "\n",
      "\n",
      "threshould: 0.58\n",
      "recall: 0.8054171855541719\n",
      "precision: 0.7502900232018561\n",
      "f1: 0.7768768768768769\n",
      "AUC-ROC 0.8877096380004152\n",
      "\n",
      "\n",
      "threshould: 0.6\n",
      "recall: 0.7966998754669987\n",
      "precision: 0.7636526410026858\n",
      "f1: 0.7798262989486516\n",
      "AUC-ROC 0.8845529897856211\n",
      "\n",
      "\n",
      "threshould: 0.62\n",
      "recall: 0.7867372353673724\n",
      "precision: 0.7753912243019331\n",
      "f1: 0.7810230258074486\n",
      "AUC-ROC 0.8806168930651926\n",
      "\n",
      "\n",
      "threshould: 0.64\n",
      "recall: 0.775840597758406\n",
      "precision: 0.7903583888360292\n",
      "f1: 0.783032207384132\n",
      "AUC-ROC 0.8764054218671482\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_log_reg2 = LogisticRegression(class_weight = 'balanced', random_state=12)\n",
    "model_log_reg2.fit(x_train, y_train)\n",
    "predicted_valid = model_log_reg2.predict_proba(x_val)\n",
    "\n",
    "probabilities_one_valid = predicted_valid[:, 1]\n",
    "\n",
    "f1_max = 0\n",
    "threshold_max = 0\n",
    "for threshold in np.arange(0, 0.9, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(y_val, predicted_valid)\n",
    "    if f1_max < f1:\n",
    "        f1_max = f1\n",
    "        threshold_max = threshold\n",
    "        print('threshould:', threshold_max)\n",
    "        print('recall:', recall_score(y_val, predicted_valid))\n",
    "        print('precision:', precision_score(y_val, predicted_valid))\n",
    "        print('f1:', f1_score(y_val, predicted_valid))\n",
    "        print('AUC-ROC', roc_auc_score(y_val, predicted_valid))\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f1** мера на валидационной выборке при **пороге = 0,64** составила **0,78**\n",
    "\n",
    "**recall** мера на валидационной выборке при **пороге = 0,64** составила **0,76**\n",
    "\n",
    "**precision** мера на валидационной выборке при **пороге = 0,64** составила **0,79**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "таким образом логистическая регрессия проходит в следующий шаг - шаг тестирования, причем не плохой результат за сравнительно малое время."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "т.к. мы изменили вес класса, напишем функцию для получения прогноза от логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_reg_pred(data):\n",
    "    predicted_valid = model_log_reg2.predict_proba(data)\n",
    "    probabilities_one_valid = predicted_valid[:, 1]\n",
    "    predicted_valid = probabilities_one_valid > 0.64\n",
    "    return(predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Решающее Дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина = 1, Порог = 0.00 | Precision = 0.101,Recall = 1.000, f1 = 0.183, AUC-ROC = 0.500\n",
      "\n",
      "Глубина = 1, Порог = 0.10 | Precision = 0.962,Recall = 0.152, f1 = 0.262, AUC-ROC = 0.575\n",
      "\n",
      "Глубина = 2, Порог = 0.10 | Precision = 0.959,Recall = 0.227, f1 = 0.367, AUC-ROC = 0.613\n",
      "\n",
      "Глубина = 3, Порог = 0.08 | Precision = 0.948,Recall = 0.273, f1 = 0.424, AUC-ROC = 0.636\n",
      "\n",
      "Глубина = 4, Порог = 0.08 | Precision = 0.945,Recall = 0.300, f1 = 0.456, AUC-ROC = 0.649\n",
      "\n",
      "Глубина = 5, Порог = 0.08 | Precision = 0.937,Recall = 0.339, f1 = 0.498, AUC-ROC = 0.668\n",
      "\n",
      "Глубина = 6, Порог = 0.08 | Precision = 0.902,Recall = 0.376, f1 = 0.531, AUC-ROC = 0.686\n",
      "\n",
      "Глубина = 7, Порог = 0.08 | Precision = 0.897,Recall = 0.399, f1 = 0.552, AUC-ROC = 0.697\n",
      "\n",
      "Глубина = 8, Порог = 0.08 | Precision = 0.902,Recall = 0.417, f1 = 0.571, AUC-ROC = 0.706\n",
      "\n",
      "Глубина = 9, Порог = 0.08 | Precision = 0.904,Recall = 0.430, f1 = 0.583, AUC-ROC = 0.712\n",
      "\n",
      "Глубина = 10, Порог = 0.06 | Precision = 0.908,Recall = 0.438, f1 = 0.591, AUC-ROC = 0.717\n",
      "\n",
      "Глубина = 11, Порог = 0.06 | Precision = 0.891,Recall = 0.459, f1 = 0.605, AUC-ROC = 0.726\n",
      "\n",
      "Глубина = 12, Порог = 0.06 | Precision = 0.872,Recall = 0.471, f1 = 0.612, AUC-ROC = 0.732\n",
      "\n",
      "Глубина = 13, Порог = 0.06 | Precision = 0.875,Recall = 0.477, f1 = 0.617, AUC-ROC = 0.735\n",
      "\n",
      "Глубина = 13, Порог = 0.08 | Precision = 0.878,Recall = 0.477, f1 = 0.618, AUC-ROC = 0.735\n",
      "\n",
      "Глубина = 14, Порог = 0.06 | Precision = 0.875,Recall = 0.493, f1 = 0.631, AUC-ROC = 0.743\n",
      "\n",
      "Глубина = 15, Порог = 0.06 | Precision = 0.860,Recall = 0.505, f1 = 0.636, AUC-ROC = 0.748\n",
      "\n",
      "Глубина = 16, Порог = 0.06 | Precision = 0.863,Recall = 0.510, f1 = 0.641, AUC-ROC = 0.750\n",
      "\n",
      "Глубина = 17, Порог = 0.06 | Precision = 0.862,Recall = 0.514, f1 = 0.644, AUC-ROC = 0.752\n",
      "\n",
      "Глубина = 17, Порог = 0.12 | Precision = 0.865,Recall = 0.513, f1 = 0.644, AUC-ROC = 0.752\n",
      "\n",
      "Глубина = 18, Порог = 0.06 | Precision = 0.867,Recall = 0.516, f1 = 0.647, AUC-ROC = 0.753\n",
      "\n",
      "Глубина = 19, Порог = 0.06 | Precision = 0.867,Recall = 0.521, f1 = 0.651, AUC-ROC = 0.756\n",
      "\n",
      "Глубина = 19, Порог = 0.18 | Precision = 0.869,Recall = 0.521, f1 = 0.651, AUC-ROC = 0.756\n",
      "\n",
      "Глубина = 20, Порог = 0.06 | Precision = 0.873,Recall = 0.525, f1 = 0.655, AUC-ROC = 0.758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_max = 0\n",
    "threshold_max = 0\n",
    "depth_max = 0\n",
    "for depth in range(1, 21, 1):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth=depth)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    probabilities_valid = model.predict_proba(x_val)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    \n",
    "    for threshold in np.arange(0, 0.9, 0.02):\n",
    "        predicted_valid = probabilities_one_valid > threshold\n",
    "        f1 = f1_score(y_val, predicted_valid)\n",
    "        if f1_max < f1:\n",
    "            f1_max = f1\n",
    "            threshold_max = threshold\n",
    "            depth_max = depth\n",
    "            precision = precision_score(y_val, predicted_valid)\n",
    "            recall = recall_score(y_val, predicted_valid)\n",
    "            f1 = f1_score(y_val, predicted_valid)\n",
    "            auc_roc = roc_auc_score(y_val, predicted_valid)\n",
    "            print(\"Глубина = {:.0f}, Порог = {:.2f} | Precision = {:.3f},Recall = {:.3f}, f1 = {:.3f}, AUC-ROC = {:.3f}\".format(depth_max, threshold_max, precision, recall, f1, auc_roc))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth' : [10, 17, 20]}\n",
    "\n",
    "dt_mod = DecisionTreeClassifier(random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid = GridSearchCV(estimator=dt_mod, param_grid=param_grid, cv=5)\n",
    "\n",
    "dt_grid.fit(x_train, y_train)\n",
    "\n",
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина = 20, Порог = 0.00 | Точность = 0.098, Полнота = 0.973, f1 = 0.179, AUC-ROC = 0.488\n",
      "\n",
      "Глубина = 20, Порог = 0.06 | Точность = 0.873, Полнота = 0.525, f1 = 0.655, AUC-ROC = 0.758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_max=0\n",
    "for threshold in np.arange(0, 0.9, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(y_val, predicted_valid)\n",
    "    if f1_max < f1:\n",
    "        f1_max = f1\n",
    "        threshold_max = threshold\n",
    "        precision = precision_score(y_val, predicted_valid)\n",
    "        recall = recall_score(y_val, predicted_valid)\n",
    "        f1 = f1_score(y_val, predicted_valid)\n",
    "        auc_roc = roc_auc_score(y_val, predicted_valid)\n",
    "        print(\"Глубина = {:.0f}, Порог = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}, f1 = {:.3f}, AUC-ROC = {:.3f}\".format(depth_max, threshold_max, precision, recall, f1, auc_roc))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающее дерево дало результат хуже, чем логистическая регрессия, f1 = 0,655, оставим дерево на этом шаге.\n",
    "\n",
    "Посмотрим что даст нам лес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "    'max_depth' : [10, 17, 20]}\n",
    "\n",
    "rf_mod = RandomForestClassifier(random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 17, 'n_estimators': 50}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid = GridSearchCV(estimator=rf_mod, param_grid=param_grid, cv=3) # в документации советуют брать cv минимум 5, но тогда очень долго думает\n",
    "\n",
    "rf_grid.fit(x_train, y_train)\n",
    "\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1  0.39382845188284515\n",
      "порог 0.1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_max = 0\n",
    "probabilities_valid = rf_grid.predict_proba(x_val)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.1, 0.9, 0.1):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(y_val, predicted_valid)\n",
    "    if f1_max < f1:\n",
    "        f1_max = f1\n",
    "        threshold_max = threshold\n",
    "        print('F1 ', f1_max)\n",
    "        print('порог', threshold_max)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1  0.6583771311370337\n",
      "порог 0.11\n",
      "\n",
      "F1  0.7061774851050486\n",
      "порог 0.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(y_val, predicted_valid)\n",
    "    if f1_max < f1:\n",
    "        f1_max = f1\n",
    "        threshold_max = threshold\n",
    "        print('F1 ', f1_max)\n",
    "        print('порог', threshold_max)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес дал результат лучший, чем решающее дерево, но не превысил результат логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostClassifier(eval_metric=\"F1\",\n",
    "                                   iterations=500, \n",
    "                                   max_depth=5, \n",
    "                                   learning_rate=0.3, \n",
    "                                   random_state=12,\n",
    "                             verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3632715\ttest: 0.3640495\tbest: 0.3640495 (0)\ttotal: 3.38s\tremaining: 28m 4s\n",
      "10:\tlearn: 0.5501500\ttest: 0.5604759\tbest: 0.5608953 (8)\ttotal: 31s\tremaining: 22m 56s\n",
      "20:\tlearn: 0.5932431\ttest: 0.6105708\tbest: 0.6105708 (20)\ttotal: 58.5s\tremaining: 22m 13s\n",
      "30:\tlearn: 0.6366673\ttest: 0.6443035\tbest: 0.6443035 (30)\ttotal: 1m 26s\tremaining: 21m 50s\n",
      "40:\tlearn: 0.6608035\ttest: 0.6634557\tbest: 0.6634557 (40)\ttotal: 1m 54s\tremaining: 21m 26s\n",
      "50:\tlearn: 0.6789953\ttest: 0.6779929\tbest: 0.6779929 (50)\ttotal: 2m 23s\tremaining: 21m 4s\n",
      "60:\tlearn: 0.6911287\ttest: 0.6866549\tbest: 0.6866549 (60)\ttotal: 2m 52s\tremaining: 20m 39s\n",
      "70:\tlearn: 0.7029144\ttest: 0.6983759\tbest: 0.6986460 (69)\ttotal: 3m 20s\tremaining: 20m 10s\n",
      "80:\tlearn: 0.7124562\ttest: 0.7071442\tbest: 0.7081340 (78)\ttotal: 3m 48s\tremaining: 19m 42s\n",
      "90:\tlearn: 0.7207800\ttest: 0.7145032\tbest: 0.7145032 (89)\ttotal: 4m 17s\tremaining: 19m 16s\n",
      "100:\tlearn: 0.7290213\ttest: 0.7172597\tbest: 0.7172597 (100)\ttotal: 4m 45s\tremaining: 18m 49s\n",
      "110:\tlearn: 0.7352481\ttest: 0.7208294\tbest: 0.7208294 (110)\ttotal: 5m 14s\tremaining: 18m 21s\n",
      "120:\tlearn: 0.7420319\ttest: 0.7238203\tbest: 0.7238203 (120)\ttotal: 5m 42s\tremaining: 17m 53s\n",
      "130:\tlearn: 0.7472718\ttest: 0.7289055\tbest: 0.7289055 (130)\ttotal: 6m 11s\tremaining: 17m 26s\n",
      "140:\tlearn: 0.7509574\ttest: 0.7326253\tbest: 0.7326253 (140)\ttotal: 6m 40s\tremaining: 16m 59s\n",
      "150:\tlearn: 0.7576018\ttest: 0.7372709\tbest: 0.7372709 (150)\ttotal: 7m 8s\tremaining: 16m 31s\n",
      "160:\tlearn: 0.7623351\ttest: 0.7384388\tbest: 0.7384388 (160)\ttotal: 7m 37s\tremaining: 16m 2s\n",
      "170:\tlearn: 0.7640778\ttest: 0.7386721\tbest: 0.7393154 (161)\ttotal: 8m 5s\tremaining: 15m 35s\n",
      "180:\tlearn: 0.7671800\ttest: 0.7406723\tbest: 0.7406723 (179)\ttotal: 8m 34s\tremaining: 15m 7s\n",
      "190:\tlearn: 0.7703236\ttest: 0.7430466\tbest: 0.7430466 (190)\ttotal: 9m 3s\tremaining: 14m 39s\n",
      "200:\tlearn: 0.7730991\ttest: 0.7444853\tbest: 0.7447591 (194)\ttotal: 9m 32s\tremaining: 14m 11s\n",
      "210:\tlearn: 0.7758631\ttest: 0.7443140\tbest: 0.7450404 (204)\ttotal: 10m 1s\tremaining: 13m 43s\n",
      "220:\tlearn: 0.7772878\ttest: 0.7445443\tbest: 0.7450404 (204)\ttotal: 10m 29s\tremaining: 13m 15s\n",
      "230:\tlearn: 0.7788572\ttest: 0.7449615\tbest: 0.7450404 (204)\ttotal: 10m 58s\tremaining: 12m 47s\n",
      "240:\tlearn: 0.7791566\ttest: 0.7461595\tbest: 0.7461595 (240)\ttotal: 11m 27s\tremaining: 12m 18s\n",
      "250:\tlearn: 0.7805582\ttest: 0.7471285\tbest: 0.7471285 (250)\ttotal: 11m 55s\tremaining: 11m 50s\n",
      "260:\tlearn: 0.7834173\ttest: 0.7493634\tbest: 0.7496361 (257)\ttotal: 12m 24s\tremaining: 11m 21s\n",
      "270:\tlearn: 0.7853547\ttest: 0.7504547\tbest: 0.7505455 (267)\ttotal: 12m 53s\tremaining: 10m 53s\n",
      "280:\tlearn: 0.7872480\ttest: 0.7512727\tbest: 0.7512727 (279)\ttotal: 13m 22s\tremaining: 10m 25s\n",
      "290:\tlearn: 0.7899009\ttest: 0.7509078\tbest: 0.7514535 (282)\ttotal: 13m 51s\tremaining: 9m 56s\n",
      "300:\tlearn: 0.7927810\ttest: 0.7514514\tbest: 0.7514535 (282)\ttotal: 14m 19s\tremaining: 9m 28s\n",
      "310:\tlearn: 0.7949129\ttest: 0.7528558\tbest: 0.7528558 (308)\ttotal: 14m 48s\tremaining: 9m\n",
      "320:\tlearn: 0.7974112\ttest: 0.7540746\tbest: 0.7540746 (317)\ttotal: 15m 17s\tremaining: 8m 31s\n",
      "330:\tlearn: 0.8001896\ttest: 0.7557803\tbest: 0.7560051 (329)\ttotal: 15m 46s\tremaining: 8m 3s\n",
      "340:\tlearn: 0.8022472\ttest: 0.7566691\tbest: 0.7567178 (337)\ttotal: 16m 14s\tremaining: 7m 34s\n",
      "350:\tlearn: 0.8043440\ttest: 0.7573794\tbest: 0.7575158 (349)\ttotal: 16m 43s\tremaining: 7m 6s\n",
      "360:\tlearn: 0.8070175\ttest: 0.7590795\tbest: 0.7590795 (359)\ttotal: 17m 12s\tremaining: 6m 37s\n",
      "370:\tlearn: 0.8090231\ttest: 0.7611699\tbest: 0.7611699 (368)\ttotal: 17m 41s\tremaining: 6m 9s\n",
      "380:\tlearn: 0.8121631\ttest: 0.7627574\tbest: 0.7632003 (377)\ttotal: 18m 10s\tremaining: 5m 40s\n",
      "390:\tlearn: 0.8126720\ttest: 0.7629975\tbest: 0.7632192 (388)\ttotal: 18m 39s\tremaining: 5m 12s\n",
      "400:\tlearn: 0.8143643\ttest: 0.7645479\tbest: 0.7645479 (400)\ttotal: 19m 8s\tremaining: 4m 43s\n",
      "410:\tlearn: 0.8158187\ttest: 0.7648006\tbest: 0.7648006 (405)\ttotal: 19m 37s\tremaining: 4m 14s\n",
      "420:\tlearn: 0.8164243\ttest: 0.7633560\tbest: 0.7648006 (405)\ttotal: 20m 6s\tremaining: 3m 46s\n",
      "430:\tlearn: 0.8183356\ttest: 0.7645161\tbest: 0.7648006 (405)\ttotal: 20m 35s\tremaining: 3m 17s\n",
      "440:\tlearn: 0.8199988\ttest: 0.7648533\tbest: 0.7653481 (432)\ttotal: 21m 3s\tremaining: 2m 49s\n",
      "450:\tlearn: 0.8218668\ttest: 0.7660714\tbest: 0.7661780 (443)\ttotal: 21m 32s\tremaining: 2m 20s\n",
      "460:\tlearn: 0.8229893\ttest: 0.7659879\tbest: 0.7662917 (453)\ttotal: 22m 1s\tremaining: 1m 51s\n",
      "470:\tlearn: 0.8243832\ttest: 0.7657143\tbest: 0.7662917 (453)\ttotal: 22m 29s\tremaining: 1m 23s\n",
      "480:\tlearn: 0.8256934\ttest: 0.7662384\tbest: 0.7665120 (476)\ttotal: 22m 58s\tremaining: 54.5s\n",
      "490:\tlearn: 0.8262181\ttest: 0.7663218\tbest: 0.7668985 (487)\ttotal: 23m 27s\tremaining: 25.8s\n",
      "499:\tlearn: 0.8270145\ttest: 0.7667618\tbest: 0.7668985 (487)\ttotal: 23m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7668985197\n",
      "bestIteration = 487\n",
      "\n",
      "Shrink model to first 488 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f08ed6975d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.fit(\n",
    "   x_train, y_train,\n",
    "   eval_set=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим результат при тестировании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.7764240024367957\n",
      "precision: 0.7790342298288508\n",
      "f1: 0.7777269260106788\n",
      "AUC-ROC 0.8755862677733014\n"
     ]
    }
   ],
   "source": [
    "print('recall:', recall_score(y_test, get_log_reg_pred(x_test)))\n",
    "print('precision:', precision_score(y_test, get_log_reg_pred(x_test)))\n",
    "print('f1:', f1_score(y_test, get_log_reg_pred(x_test)))\n",
    "print('AUC-ROC', roc_auc_score(y_test, get_log_reg_pred(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сохраним значения в переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_lr = 0.776\n",
    "precision_lr =  0.779\n",
    "f1_lr =  0.777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Cat-Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.6612854096862626\n",
      "precision: 0.8974782968168665\n",
      "f1: 0.7614871974745703\n",
      "AUC-ROC 0.8263118861786999\n"
     ]
    }
   ],
   "source": [
    "print('recall:', recall_score(y_test, cb_model.predict(x_test)))\n",
    "print('precision:', precision_score(y_test, cb_model.predict(x_test)))\n",
    "print('f1:', f1_score(y_test, cb_model.predict(x_test)))\n",
    "print('AUC-ROC', roc_auc_score(y_test, cb_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_cb = 0.661\n",
    "precision_cb = 0.897\n",
    "f1_cb = 0.761\n",
    "AUC_ROC_cb = 0.826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost показал результат чуть хуже линейной регрессии **f1** = **0.76**,\n",
    "но precision больше, то есть ложно положительных меньше, но зато больше ложно отрицательных.\n",
    "\n",
    "Чтобы было нагляднее, давайте посмотрим на confusion_matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27909,   723],\n",
       "       [  734,  2549]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, get_log_reg_pred(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cat_boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28384,   248],\n",
       "       [ 1112,  2171]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, cb_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическаая регрессия меньше пропускает токсичные комментарии, что для нас крайне важно. И учится и работает быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили в данном проекте 4 модели:\n",
    "    \n",
    "        1. LogisticClassifier\n",
    "        2. CatBoostClassifier\n",
    "        3. RandomForestClassifier\n",
    "        4. DesicionTreeClassifier\n",
    "        \n",
    "Основное требование - f1_score больше 0,75.\n",
    "Логистическая регрессия показала 0,777, кэт-бустинг 0,76, но!\n",
    "\n",
    "Логистическая регрессия меньше пропускает токсических комментариев, быстрее учится и работает, менее требовательна к системным ресурсам.\n",
    "\n",
    "Поэтому из сделаных мною моделей - логистическая регрессия подходит лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой работе я не стал писать дополнительных функций, но если бы пришлось дополнить модель, если бы понадобилась функция, которая разом уберет комментарии, которые может даже и не велеки по количеству слов или символов, хотя они все максимально длинные.\n",
    "\n",
    "То я бы пошел по следующему алгоритму:\n",
    "\n",
    "    преобразовал комментарий в мешок слов. \n",
    "    проверил бы соответствует такой вектор условиям:\n",
    "            \n",
    "            - короткий вектор (сейчас не буду определять число,т.к. не проводил аналитику в данном направлении)\n",
    "            - большинство значений одинаково, например [10,10,9]\n",
    "    \n",
    "    если соответствует - сразу удаляем, не напрягая модератора и модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
